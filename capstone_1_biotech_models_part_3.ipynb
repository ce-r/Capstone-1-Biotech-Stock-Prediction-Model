{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "capstone 1 biotech models_part_3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4erpzjuDfgD8",
        "colab_type": "text"
      },
      "source": [
        "#INTRO\n",
        "This is the final notebook of 3 with the final focus on the modeling phase and a time series approach to price prediction\n",
        "If you are at a loss in the process, please visit the previous two notebooks\n",
        "\n",
        "Attention:\n",
        "Please take note of the code comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lcw_l73AmowA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pandas_datareader import data as dr\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMG5iUbVnATG",
        "colab_type": "text"
      },
      "source": [
        "Data Loading Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBuenKHko_mi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_date = '2000-01-01'\n",
        "end_date = '2019-01-05'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiIm77lpmosM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getTicks(items):\n",
        "  symbols = []\n",
        "  for i in items:\n",
        "    try:\n",
        "      data = dr.get_data_yahoo(i, start_date, end_date)\n",
        "    except Exception as e:\n",
        "      print(\"there was a problem with {}\".format(i))\n",
        "    else:\n",
        "      symbols.append(i)\n",
        "  return symbols"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQXSHhUwmwfU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_ticks = [\n",
        "            'NVS'                \n",
        "]\n",
        "\n",
        "adj = getTicks(sample_ticks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5X6UZi0Y2iO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = dr.get_data_yahoo(adj, start_date, end_date)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHnx6cgUY6sq",
        "colab_type": "code",
        "outputId": "06a4d2ab-e2d1-4e24-c3b7-7a9f58604a5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th>Attributes</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Adj Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Symbols</th>\n",
              "      <th>NVS</th>\n",
              "      <th>NVS</th>\n",
              "      <th>NVS</th>\n",
              "      <th>NVS</th>\n",
              "      <th>NVS</th>\n",
              "      <th>NVS</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000-01-03</th>\n",
              "      <td>33.154121</td>\n",
              "      <td>32.370071</td>\n",
              "      <td>32.594086</td>\n",
              "      <td>32.594086</td>\n",
              "      <td>133200.0</td>\n",
              "      <td>17.756123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-04</th>\n",
              "      <td>33.490143</td>\n",
              "      <td>31.978046</td>\n",
              "      <td>31.978046</td>\n",
              "      <td>31.978046</td>\n",
              "      <td>243200.0</td>\n",
              "      <td>17.420527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-05</th>\n",
              "      <td>33.826164</td>\n",
              "      <td>31.810036</td>\n",
              "      <td>32.118057</td>\n",
              "      <td>32.118057</td>\n",
              "      <td>144600.0</td>\n",
              "      <td>17.496799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-06</th>\n",
              "      <td>33.378136</td>\n",
              "      <td>31.922043</td>\n",
              "      <td>32.818100</td>\n",
              "      <td>32.818100</td>\n",
              "      <td>579200.0</td>\n",
              "      <td>17.878160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-07</th>\n",
              "      <td>34.274193</td>\n",
              "      <td>32.706093</td>\n",
              "      <td>33.322132</td>\n",
              "      <td>33.322132</td>\n",
              "      <td>89900.0</td>\n",
              "      <td>18.152739</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Attributes       High        Low       Open      Close    Volume  Adj Close\n",
              "Symbols           NVS        NVS        NVS        NVS       NVS        NVS\n",
              "Date                                                                       \n",
              "2000-01-03  33.154121  32.370071  32.594086  32.594086  133200.0  17.756123\n",
              "2000-01-04  33.490143  31.978046  31.978046  31.978046  243200.0  17.420527\n",
              "2000-01-05  33.826164  31.810036  32.118057  32.118057  144600.0  17.496799\n",
              "2000-01-06  33.378136  31.922043  32.818100  32.818100  579200.0  17.878160\n",
              "2000-01-07  34.274193  32.706093  33.322132  33.322132   89900.0  18.152739"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9L1T9hJYuwq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prices = df.loc[:,('Adj Close',slice(None))]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXWwZL5VYudv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prices.columns = prices.columns.droplevel(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oB25F9WAURO3",
        "colab_type": "code",
        "outputId": "a0d69cb8-1733-46eb-f7a8-7721b4eed76c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "source": [
        "prices.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Symbols</th>\n",
              "      <th>NVS</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000-01-03</th>\n",
              "      <td>17.756123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-04</th>\n",
              "      <td>17.420527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-05</th>\n",
              "      <td>17.496799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-06</th>\n",
              "      <td>17.878160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-07</th>\n",
              "      <td>18.152739</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Symbols           NVS\n",
              "Date                 \n",
              "2000-01-03  17.756123\n",
              "2000-01-04  17.420527\n",
              "2000-01-05  17.496799\n",
              "2000-01-06  17.878160\n",
              "2000-01-07  18.152739"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GItMRwH0-8h6",
        "colab_type": "code",
        "outputId": "046ef27e-a54d-4d96-b3df-4c4551e01243",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "source": [
        "p = prices.loc['2000-01-01':'2000-04-01']\n",
        "p.tail()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Symbols</th>\n",
              "      <th>NVS</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000-03-27</th>\n",
              "      <td>16.108650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-03-28</th>\n",
              "      <td>16.078140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-03-29</th>\n",
              "      <td>16.017122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-03-30</th>\n",
              "      <td>16.108650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-03-31</th>\n",
              "      <td>16.688316</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Symbols           NVS\n",
              "Date                 \n",
              "2000-03-27  16.108650\n",
              "2000-03-28  16.078140\n",
              "2000-03-29  16.017122\n",
              "2000-03-30  16.108650\n",
              "2000-03-31  16.688316"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK4ifIIdwE0W",
        "colab_type": "code",
        "outputId": "8f2ab5ce-2281-440c-f501-2390119d36a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "pip install tbats"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tbats\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/f2/04545b598030cd72807847d9230a5db619658be3a650e112ed18acb3a122/tbats-1.0.9-py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.6MB/s \n",
            "\u001b[?25hCollecting pmdarima\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/1a/32945c19306212fd08547369f40c8965bbc9e18652bb241766dfab398710/pmdarima-1.5.2-cp36-cp36m-manylinux1_x86_64.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 10.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from tbats) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from tbats) (0.22.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tbats) (1.17.5)\n",
            "Requirement already satisfied: statsmodels>=0.10.0 in /usr/local/lib/python3.6/dist-packages (from pmdarima->tbats) (0.10.2)\n",
            "Requirement already satisfied: Cython>=0.29 in /usr/local/lib/python3.6/dist-packages (from pmdarima->tbats) (0.29.14)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.6/dist-packages (from pmdarima->tbats) (0.25.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from pmdarima->tbats) (0.14.1)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels>=0.10.0->pmdarima->tbats) (0.5.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->pmdarima->tbats) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->pmdarima->tbats) (2.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.0->statsmodels>=0.10.0->pmdarima->tbats) (1.12.0)\n",
            "Installing collected packages: pmdarima, tbats\n",
            "Successfully installed pmdarima-1.5.2 tbats-1.0.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJdw40qMwIHY",
        "colab_type": "code",
        "outputId": "4b48faf6-8799-4ab0-bff3-abd24ae4e6d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "pip install pyramid.arima"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyramid.arima\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/84/57422f2a6ade3161c586545e38b518ba1b7ab30ee4a4acc29110c0aba2bc/pyramid_arima-0.9.0-cp36-cp36m-manylinux1_x86_64.whl (597kB)\n",
            "\r\u001b[K     |▌                               | 10kB 19.9MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 3.3MB/s eta 0:00:01\r\u001b[K     |█▋                              | 30kB 4.7MB/s eta 0:00:01\r\u001b[K     |██▏                             | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |██▊                             | 51kB 3.8MB/s eta 0:00:01\r\u001b[K     |███▎                            | 61kB 4.4MB/s eta 0:00:01\r\u001b[K     |███▉                            | 71kB 5.1MB/s eta 0:00:01\r\u001b[K     |████▍                           | 81kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 92kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 102kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 112kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 122kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 133kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 143kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 153kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 163kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 174kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 184kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 194kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 204kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 215kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 225kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 235kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 245kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 256kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 266kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 276kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 286kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████                | 296kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 307kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 317kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 327kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 337kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 348kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 358kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 368kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 378kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 389kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 399kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 409kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 419kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 430kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 440kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 450kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 460kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 471kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 481kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 491kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 501kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 512kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 522kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 532kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 542kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 552kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 563kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 573kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 583kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 593kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 604kB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: Cython>=0.23 in /usr/local/lib/python3.6/dist-packages (from pyramid.arima) (0.29.14)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.6/dist-packages (from pyramid.arima) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.17 in /usr/local/lib/python3.6/dist-packages (from pyramid.arima) (0.22.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from pyramid.arima) (0.10.2)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.6/dist-packages (from pyramid.arima) (1.17.5)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.6/dist-packages (from pyramid.arima) (0.25.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.17->pyramid.arima) (0.14.1)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels>=0.9.0->pyramid.arima) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->pyramid.arima) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->pyramid.arima) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.0->statsmodels>=0.9.0->pyramid.arima) (1.12.0)\n",
            "Installing collected packages: pyramid.arima\n",
            "Successfully installed pyramid.arima\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BV4ZzMjSWOl4",
        "colab_type": "code",
        "outputId": "4fdd4738-850a-4e46-8426-1b6e4723742b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "pip install prophet"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting prophet\n",
            "  Downloading https://files.pythonhosted.org/packages/1b/1c/61c969e76119a8257220869a6b3b57cd2ad4fbe0fd69b9b6845bfcf135aa/prophet-0.1.1.tar.gz\n",
            "Requirement already satisfied: pytz>=2014.9 in /usr/local/lib/python3.6/dist-packages (from prophet) (2018.9)\n",
            "Requirement already satisfied: pandas>=0.15.1 in /usr/local/lib/python3.6/dist-packages (from prophet) (0.25.3)\n",
            "Requirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from prophet) (1.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.15.1->prophet) (2.6.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.15.1->prophet) (1.17.5)\n",
            "Building wheels for collected packages: prophet\n",
            "  Building wheel for prophet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prophet: filename=prophet-0.1.1-cp36-none-any.whl size=12168 sha256=15c1d37d84624def348883557a741a81b03cdc9268e7cbe2e80860cfe2a6c672\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/3e/f3/1c536bf1f871f818686e7fbf31cab18d52787a72dea8640756\n",
            "Successfully built prophet\n",
            "Installing collected packages: prophet\n",
            "Successfully installed prophet-0.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N57CcK6Ono-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tbats import TBATS\n",
        "from pmdarima import auto_arima\n",
        "from fbprophet import Prophet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpSMqaX3nG4m",
        "colab_type": "text"
      },
      "source": [
        "MODELS:\n",
        "Forecasting 30-90 Days"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLDmOPrDkH7H",
        "colab_type": "text"
      },
      "source": [
        "MAPE is the error metric used in all models and called in the rolling_cv(), which splits our time series data for modeling.\n",
        "MAPE stands for mean average percentage error and it calculates the mean of all errors as percentage change of predicted and true values\n",
        "MAPE was chosen for it's simplicity to code. it's not uncommon to use this metric for time series forecasting "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EUmVtl_UzLC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Error metric - MAPE\n",
        "\n",
        "def mape(y_true, y_pred): \n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ-EP1H4l6iW",
        "colab_type": "text"
      },
      "source": [
        "#Modeling Phase: \n",
        "Models were considered appropriate for time series were used and were chosen based on their ranging complexities from the simple average to the lstm.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVV77BvJoK30",
        "colab_type": "text"
      },
      "source": [
        "Simple Average"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxgeGwKBUl7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sam(ts):\n",
        "    avg = ts.mean()\n",
        "    return(avg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-ExBTBuoYIz",
        "colab_type": "text"
      },
      "source": [
        "#rolling_cv() was written to automate the data split and modeling process and does so in a one step manner using a sample column classifier(for training and crossVal) with datetime index conditioning. rolling_cv() predicts one point at a time until it passes through the entire validation set using a small 3 month sample of an 18 year data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFOSMBP5U6kh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rolling_cv(data):\n",
        "  final_results_df = pd.DataFrame()\n",
        "  \n",
        "  for local_ticker in data.columns:\n",
        "    df = data[[local_ticker]]\n",
        "    df['sample'] = np.where(df.index < '2000-02-15', 'train', 'test')\n",
        "    df['sample'] = np.where((df.index >= '2000-02-15') & (df.index <= '2000-03-15'), 'crossVal', df['sample'])\n",
        "\n",
        "\n",
        "    # create empty column to capture one step predictions\n",
        "    df['prediction'] = np.nan\n",
        "   \n",
        "    # Get dates during the cross validation slice and sort them\n",
        "    crossVal_Dates = df.index[df['sample'] == 'crossVal'].sort_values()\n",
        "   \n",
        "    # roll the train window forward by one data point with every iteration and predict next point\n",
        "    for crossDate in crossVal_Dates:\n",
        "        local_train_timeSeries = df[[local_ticker]][df.index < crossDate]\n",
        "        prediction = sam(local_train_timeSeries[local_ticker])#****\n",
        "        df.loc[df.index == crossDate, 'prediction'] = prediction\n",
        "   \n",
        "    # filter the predictions from df to calculate error\n",
        "    crossVal_df = df[df.index.isin(crossVal_Dates)]    \n",
        "\n",
        "    mape_local_df = (mape(crossVal_df[local_ticker], crossVal_df['prediction']))  \n",
        "    #return(mean_absolute_percentage_error(crossVal_df[local_ticker], crossVal_df['prediction'])) \n",
        "    local_results_df = pd.DataFrame({'ticker' : local_ticker,\n",
        "                                    'MAPE' : mape_local_df}, index = [0])\n",
        "    final_results_df = final_results_df.append(local_results_df)\n",
        "  return (final_results_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiGwLDc2qZEu",
        "colab_type": "code",
        "outputId": "893928c5-7838-4b19-ca56-cfedc5a719f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "source": [
        "rolling_cv(p)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ticker</th>\n",
              "      <th>MAPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NVS</td>\n",
              "      <td>6.481251</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  ticker      MAPE\n",
              "0    NVS  6.481251"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NDamioqmFdz",
        "colab_type": "text"
      },
      "source": [
        "AutoArima: an AutoRegressive model using time lag variables for forecasting and automatically find the optimal parameters p, d, q.\n",
        "For more details, please visit the capstone report.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J28sacsTFOHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def autoarima(ts,idx):\n",
        "  \n",
        "  model = auto_arima(ts, start_p=1, start_q=1, d=0,max_p=5,max_d= 2, max_q=5, error_action='ignore',suppress_warnings=True)\n",
        "  #trace=True,\n",
        "  model.fit(ts)\n",
        "\n",
        "  forecast = model.predict(n_periods=1)# n_periods\n",
        "  fc = pd.DataFrame(forecast,index = idx,columns=['Prediction'])# valid.index => idx, index must be called with a collection of some kind\n",
        "  return (fc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvUL2hfR_iWP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def aa_cv(data):\n",
        "  final_results_df = pd.DataFrame()\n",
        "  \n",
        "  for local_ticker in data.columns:\n",
        "    df = data[[local_ticker]]\n",
        "    df['sample'] = np.where(df.index < '2000-02-15', 'train', 'test')\n",
        "    df['sample'] = np.where((df.index >= '2000-02-15') & (df.index <= '2000-03-15'), 'crossVal', df['sample'])\n",
        "\n",
        "\n",
        "    # create empty column to capture one step predictions\n",
        "    df['prediction'] = np.nan\n",
        "   \n",
        "    # Get dates during the cross validation slice and sort them\n",
        "    crossVal_Dates = df.index[df['sample'] == 'crossVal'].sort_values()\n",
        "   \n",
        "    # roll the train window forward by one data point with every iteration and predict next point\n",
        "    for crossDate in crossVal_Dates:\n",
        "        local_train_timeSeries = df[[local_ticker]][df.index < crossDate]\n",
        "        #prediction = autoarima(local_train_timeSeries[local_ticker])\n",
        "        prediction = autoarima(local_train_timeSeries[local_ticker],df.loc[df.index == crossDate].index)#****\n",
        "        #print(prediction.values)\n",
        "        df.loc[df.index == crossDate, 'prediction'] = prediction.values\n",
        "   \n",
        "    # filter the predictions from df to calculate error\n",
        "    crossVal_df = df[df.index.isin(crossVal_Dates)]   \n",
        "\n",
        "    mape_local_df = (mape(crossVal_df[local_ticker], crossVal_df['prediction']))  \n",
        "    #return(mean_absolute_percentage_error(crossVal_df[local_ticker], crossVal_df['prediction'])) \n",
        "    local_results_df = pd.DataFrame({'ticker' : local_ticker,\n",
        "                                    'MAPE' : mape_local_df}, index = [0])\n",
        "    final_results_df = final_results_df.append(local_results_df)\n",
        "  return (final_results_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1hIvNE4v4Im",
        "colab_type": "code",
        "outputId": "4103d711-3866-473f-805a-02ffe58fd830",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "source": [
        "p.tail()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Symbols</th>\n",
              "      <th>NVS</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000-03-27</th>\n",
              "      <td>16.108650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-03-28</th>\n",
              "      <td>16.078140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-03-29</th>\n",
              "      <td>16.017122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-03-30</th>\n",
              "      <td>16.108650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-03-31</th>\n",
              "      <td>16.688316</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Symbols           NVS\n",
              "Date                 \n",
              "2000-03-27  16.108650\n",
              "2000-03-28  16.078140\n",
              "2000-03-29  16.017122\n",
              "2000-03-30  16.108650\n",
              "2000-03-31  16.688316"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MXJHSdCUgZg",
        "colab_type": "code",
        "outputId": "ace8c1dc-7825-4c45-d6ac-3cc1cff60d65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "source": [
        "aa_cv(p)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ticker</th>\n",
              "      <th>MAPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NVS</td>\n",
              "      <td>1.499655</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  ticker      MAPE\n",
              "0    NVS  1.499655"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bnNd1DBsvMI",
        "colab_type": "text"
      },
      "source": [
        "Fourier Transform for AutoArima"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v4t7hFJuziz",
        "colab_type": "code",
        "outputId": "02ed3a5a-3d19-44d2-8cda-1d04513e8b34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        }
      },
      "source": [
        "test = df.loc[:,(['Open', 'Close','High','Adj Close','Low'],slice(None))]\n",
        "test.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th>Attributes</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Symbols</th>\n",
              "      <th>NVS</th>\n",
              "      <th>NVS</th>\n",
              "      <th>NVS</th>\n",
              "      <th>NVS</th>\n",
              "      <th>NVS</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000-01-03</th>\n",
              "      <td>33.154121</td>\n",
              "      <td>32.370071</td>\n",
              "      <td>32.594086</td>\n",
              "      <td>32.594086</td>\n",
              "      <td>17.756123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-04</th>\n",
              "      <td>33.490143</td>\n",
              "      <td>31.978046</td>\n",
              "      <td>31.978046</td>\n",
              "      <td>31.978046</td>\n",
              "      <td>17.420527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-05</th>\n",
              "      <td>33.826164</td>\n",
              "      <td>31.810036</td>\n",
              "      <td>32.118057</td>\n",
              "      <td>32.118057</td>\n",
              "      <td>17.496799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-06</th>\n",
              "      <td>33.378136</td>\n",
              "      <td>31.922043</td>\n",
              "      <td>32.818100</td>\n",
              "      <td>32.818100</td>\n",
              "      <td>17.878160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-07</th>\n",
              "      <td>34.274193</td>\n",
              "      <td>32.706093</td>\n",
              "      <td>33.322132</td>\n",
              "      <td>33.322132</td>\n",
              "      <td>18.152739</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Attributes       High        Low       Open      Close  Adj Close\n",
              "Symbols           NVS        NVS        NVS        NVS        NVS\n",
              "Date                                                             \n",
              "2000-01-03  33.154121  32.370071  32.594086  32.594086  17.756123\n",
              "2000-01-04  33.490143  31.978046  31.978046  31.978046  17.420527\n",
              "2000-01-05  33.826164  31.810036  32.118057  32.118057  17.496799\n",
              "2000-01-06  33.378136  31.922043  32.818100  32.818100  17.878160\n",
              "2000-01-07  34.274193  32.706093  33.322132  33.322132  18.152739"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jhjiPDyu6Cf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.columns = test.columns.droplevel(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NS7NBfEAuM6c",
        "colab_type": "text"
      },
      "source": [
        "Transform data for modeling with fourier transform values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ydf53UEsu2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ftransform(data):\n",
        "    data = data.reset_index()\n",
        "    data_FT = data[['Date', 'Adj Close']]\n",
        "    close_fft = np.fft.fft(np.asarray(data_FT['Adj Close'].tolist()))\n",
        "    close_fft = np.fft.ifft(close_fft)\n",
        "    #close_fft\n",
        "    fft_df = pd.DataFrame({'fft':close_fft})\n",
        "    #print(fft_df.tail())\n",
        "    fft_df['absolute'] = fft_df['fft'].apply(lambda x: np.abs(x))\n",
        "    fft_df['angle'] = fft_df['fft'].apply(lambda x: np.angle(x))\n",
        "    fft_list = np.asarray(fft_df['fft'].tolist())\n",
        "    fft_list_m10= np.copy(fft_list) \n",
        "    fft_list_m10[100:-100]=0\n",
        "    # 100 components\n",
        "    data['Fourier'] = pd.DataFrame(fft_list_m10).apply(lambda x: np.abs(x))\n",
        "    data = data.set_index('Date')\n",
        "    data = data[['Fourier']]\n",
        "    print(data[-10:-1])\n",
        "    #dataset['absolute'] = dataset['Fourier'].apply(lambda x: np.abs(x))\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCQwZGf8tAsO",
        "colab_type": "code",
        "outputId": "3e322933-e969-41cc-c505-17437fb9715c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "dta = ftransform(test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attributes    Fourier\n",
            "Date                 \n",
            "2018-12-20  73.109093\n",
            "2018-12-21  72.345284\n",
            "2018-12-24  71.598831\n",
            "2018-12-26  73.577797\n",
            "2018-12-27  72.970222\n",
            "2018-12-28  74.003105\n",
            "2018-12-31  74.480492\n",
            "2019-01-02  72.961540\n",
            "2019-01-03  73.551765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2NrUg2Qsupa",
        "colab_type": "code",
        "outputId": "1fdf1759-2647-499f-fe7b-a88a2647c76d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "source": [
        "dta  = dta.loc['2000-01-01':'2000-04-01']\n",
        "dta.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Attributes</th>\n",
              "      <th>Fourier</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000-03-27</th>\n",
              "      <td>16.108650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-03-28</th>\n",
              "      <td>16.078140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-03-29</th>\n",
              "      <td>16.017122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-03-30</th>\n",
              "      <td>16.108650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-03-31</th>\n",
              "      <td>16.688316</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Attributes    Fourier\n",
              "Date                 \n",
              "2000-03-27  16.108650\n",
              "2000-03-28  16.078140\n",
              "2000-03-29  16.017122\n",
              "2000-03-30  16.108650\n",
              "2000-03-31  16.688316"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGmsH1hNvX98",
        "colab_type": "code",
        "outputId": "ceda1961-db34-4ff5-a9dc-1b94edfeab5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "source": [
        "aa_cv(dta)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ticker</th>\n",
              "      <th>MAPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fourier</td>\n",
              "      <td>1.499665</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    ticker      MAPE\n",
              "0  Fourier  1.499665"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCGG-FzWmKva",
        "colab_type": "text"
      },
      "source": [
        "TBATS: stands for Trigonometric seasonality, Box-Cox transformation, ARMA errors, Trend and Seasonal components. It is an Autoregressive model fortified with trigonometric and statistical qualities that should account for seasonality. For more details, follow the link: https://medium.com/intive-developers/forecasting-time-series-with-multiple-seasonalities-using-tbats-in-python-398a00ac0e8a"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ai4nGm_5PmG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit the model\n",
        "def tbats(ts):\n",
        "  estimator = TBATS(seasonal_periods=(7, 30),use_box_cox=False)\n",
        "  model = estimator.fit(ts)\n",
        "\n",
        "  model_forecast = model.forecast(steps=1)\n",
        "  return model_forecast"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VwQADidPEpI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tbats_cv(data):\n",
        "  final_results_df = pd.DataFrame()\n",
        "  \n",
        "  for local_ticker in data.columns:\n",
        "    df = data[[local_ticker]]\n",
        "    df['sample'] = np.where(df.index < '2000-02-15', 'train', 'test')\n",
        "    df['sample'] = np.where((df.index >= '2000-02-15') & (df.index <= '2000-03-15'), 'crossVal', df['sample'])\n",
        "\n",
        "\n",
        "    # create empty column to capture one step predictions\n",
        "    df['prediction'] = np.nan\n",
        "   \n",
        "    # Get dates during the cross validation slice and sort them\n",
        "    crossVal_Dates = df.index[df['sample'] == 'crossVal'].sort_values()\n",
        "   \n",
        "    # roll the train window forward by one data point with every iteration and predict next point\n",
        "    for crossDate in crossVal_Dates:\n",
        "        local_train_timeSeries = df[[local_ticker]][df.index < crossDate]\n",
        "        #prediction = autoarima(local_train_timeSeries[local_ticker])\n",
        "        prediction = tbats(local_train_timeSeries[local_ticker])#****\n",
        "        df.loc[df.index == crossDate, 'prediction'] = prediction\n",
        "   \n",
        "    # filter the predictions from df to calculate error\n",
        "    crossVal_df = df[df.index.isin(crossVal_Dates)]    \n",
        "\n",
        "    mape_local_df = (mape(crossVal_df[local_ticker], crossVal_df['prediction']))  \n",
        "    #return(mean_absolute_percentage_error(crossVal_df[local_ticker], crossVal_df['prediction'])) \n",
        "    local_results_df = pd.DataFrame({'ticker' : local_ticker,\n",
        "                                    'MAPE' : mape_local_df}, index = [0])\n",
        "    final_results_df = final_results_df.append(local_results_df)\n",
        "  return (final_results_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzBszpEPPV4I",
        "colab_type": "code",
        "outputId": "4dc1b194-819d-4905-bcaa-d75c9412d5a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "source": [
        "tbats_cv(p)\n",
        "# about 10 minutes to complete"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ticker</th>\n",
              "      <th>MAPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NVS</td>\n",
              "      <td>3.126702</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  ticker      MAPE\n",
              "0    NVS  3.126702"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8QAQtrtmXgC",
        "colab_type": "text"
      },
      "source": [
        "FB Prophet: a modeling approach using facebooks import.\n",
        "It is based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. It works best with time series that have strong seasonal effects and several seasons of historical data. \n",
        "In this case, it is applied to rolling_cv() and performs as a result. It performs better by itself. For more details: https://facebook.github.io/prophet/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kO6XJbymXLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prophet(df,local_ticker):\n",
        "  fb = df.reset_index()\n",
        "  fb = fb.rename(columns = {'Date':'ds', local_ticker:'y'})\n",
        "  m = Prophet()\n",
        "  m.fit(fb)\n",
        "  future = m.make_future_dataframe(periods=1)\n",
        "  forecast = m.predict(future)\n",
        "  return forecast.iloc[-1][-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWTpqzfkiVQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fb_cv(data):\n",
        "  final_results_df = pd.DataFrame()\n",
        "  \n",
        "  for local_ticker in data.columns:\n",
        "    df = data[[local_ticker]]\n",
        "    df['sample'] = np.where(df.index < '2000-02-15', 'train', 'test')\n",
        "    df['sample'] = np.where((df.index >= '2000-02-15') & (df.index <= '2000-03-15'), 'crossVal', df['sample'])\n",
        "\n",
        "\n",
        "    # create empty column to capture one step predictions\n",
        "    df['prediction'] = np.nan\n",
        "   \n",
        "    # Get dates during the cross validation slice and sort them\n",
        "    crossVal_Dates = df.index[df['sample'] == 'crossVal'].sort_values()\n",
        "   \n",
        "    # roll the train window forward by one data point with every iteration and predict next point\n",
        "    for crossDate in crossVal_Dates:\n",
        "        local_train_timeSeries = df[[local_ticker]][df.index < crossDate]\n",
        "        #prediction = autoarima(local_train_timeSeries[local_ticker])\n",
        "        prediction = prophet(local_train_timeSeries[local_ticker],local_ticker)#****\n",
        "        df.loc[df.index == crossDate, 'prediction'] = prediction\n",
        "   \n",
        "    # filter the predictions from df to calculate error\n",
        "    crossVal_df = df[df.index.isin(crossVal_Dates)]    \n",
        "\n",
        "    mape_local_df = (mape(crossVal_df[local_ticker], crossVal_df['prediction']))  \n",
        "    #return(mean_absolute_percentage_error(crossVal_df[local_ticker], crossVal_df['prediction'])) \n",
        "    local_results_df = pd.DataFrame({'ticker' : local_ticker,\n",
        "                                    'MAPE' : mape_local_df}, index = [0])\n",
        "    final_results_df = final_results_df.append(local_results_df)\n",
        "  return (final_results_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZVJW0JOioc8",
        "colab_type": "code",
        "outputId": "efb6d14b-aef6-4cd8-dcb3-2096bc503c09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 895
        }
      },
      "source": [
        "fb_cv(p)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:fbprophet:n_changepoints greater than number of observations.Using 23.\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:fbprophet:n_changepoints greater than number of observations.Using 23.\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:fbprophet:n_changepoints greater than number of observations.Using 24.\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ticker</th>\n",
              "      <th>MAPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NVS</td>\n",
              "      <td>36.877404</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  ticker       MAPE\n",
              "0    NVS  36.877404"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kIIkOYurVuW",
        "colab_type": "text"
      },
      "source": [
        "#LSTM: departure from AutoRegression in favor of Neural Network Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJCkXslhzHiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pip install tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTa5otqSrUdY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "a476cfbf-d53e-497c-d715-b899681921f5"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Activation"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy-u1l5mrUaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Gx5EnDorUQS",
        "colab_type": "code",
        "outputId": "e4dba0a5-c709-4656-b5fb-cec5c3d21193",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "source": [
        "dataset = test.copy().loc['2000-01-01':'2000-04-01']\n",
        "dataset.tail()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Attributes</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000-03-27</th>\n",
              "      <td>29.793907</td>\n",
              "      <td>29.065861</td>\n",
              "      <td>29.569893</td>\n",
              "      <td>29.569893</td>\n",
              "      <td>16.108650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-03-28</th>\n",
              "      <td>30.017921</td>\n",
              "      <td>29.233871</td>\n",
              "      <td>29.513889</td>\n",
              "      <td>29.513889</td>\n",
              "      <td>16.078140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-03-29</th>\n",
              "      <td>30.241936</td>\n",
              "      <td>28.897850</td>\n",
              "      <td>29.401882</td>\n",
              "      <td>29.401882</td>\n",
              "      <td>16.017122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-03-30</th>\n",
              "      <td>30.129929</td>\n",
              "      <td>29.121864</td>\n",
              "      <td>29.569893</td>\n",
              "      <td>29.569893</td>\n",
              "      <td>16.108650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-03-31</th>\n",
              "      <td>30.969982</td>\n",
              "      <td>29.513889</td>\n",
              "      <td>30.633961</td>\n",
              "      <td>30.633961</td>\n",
              "      <td>16.688316</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Attributes       High        Low       Open      Close  Adj Close\n",
              "Date                                                             \n",
              "2000-03-27  29.793907  29.065861  29.569893  29.569893  16.108650\n",
              "2000-03-28  30.017921  29.233871  29.513889  29.513889  16.078140\n",
              "2000-03-29  30.241936  28.897850  29.401882  29.401882  16.017122\n",
              "2000-03-30  30.129929  29.121864  29.569893  29.569893  16.108650\n",
              "2000-03-31  30.969982  29.513889  30.633961  30.633961  16.688316"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9SaUsy_0T64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# unnecessary, preferred reverse indexing \n",
        "dataset = dataset.reindex(index = dataset.index[::-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9lFPanGyNLO",
        "colab_type": "code",
        "outputId": "19e47a05-b009-41a7-d236-d89fb2d25a35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "dataset.index[:10]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatetimeIndex(['2000-03-31', '2000-03-30', '2000-03-29', '2000-03-28',\n",
              "               '2000-03-27', '2000-03-24', '2000-03-23', '2000-03-22',\n",
              "               '2000-03-21', '2000-03-20'],\n",
              "              dtype='datetime64[ns]', name='Date', freq=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYF515zL0EDf",
        "colab_type": "text"
      },
      "source": [
        "Aggregating values over Columns to create one signal/Column vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpGfv_sl06kE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# OpenHighLowClose = OHLC\n",
        "OHLC_avg = p.mean(axis = 1)\n",
        "# p defined in the first few cells above "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFpB6VX61xWZ",
        "colab_type": "code",
        "outputId": "dc58c520-7311-4739-a1df-aa26dbea9fb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "OHLC_avg[:10]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date\n",
              "2000-01-03    17.756123\n",
              "2000-01-04    17.420527\n",
              "2000-01-05    17.496799\n",
              "2000-01-06    17.878160\n",
              "2000-01-07    18.152739\n",
              "2000-01-10    18.183243\n",
              "2000-01-11    17.817141\n",
              "2000-01-12    17.725615\n",
              "2000-01-13    17.939177\n",
              "2000-01-14    17.878160\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZohOhDTi09WW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare ts data\n",
        "OHLC_avg = np.reshape(OHLC_avg.values, (len(OHLC_avg),1)) \n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "OHLC_avg = scaler.fit_transform(OHLC_avg)\n",
        "\n",
        "# transforming data w/ scaler for lstm model w/o time\n",
        "# as single element row vectors in a column"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sty1yFpb18z9",
        "colab_type": "code",
        "outputId": "bd2c87bb-b5e3-489c-bcea-d30924f561c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "OHLC_avg[:10]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.88034256],\n",
              "       [0.78632554],\n",
              "       [0.80769336],\n",
              "       [0.91453139],\n",
              "       [0.99145426],\n",
              "       [1.        ],\n",
              "       [0.89743671],\n",
              "       [0.87179575],\n",
              "       [0.931625  ],\n",
              "       [0.91453139]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_faL2Fl0_1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train test split\n",
        "train_OHLC = int(len(OHLC_avg) * 0.75)\n",
        "test_OHLC = len(OHLC_avg) - train_OHLC\n",
        "train_OHLC, test_OHLC = OHLC_avg[0:train_OHLC,:], OHLC_avg[train_OHLC:len(OHLC_avg),:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLQD2Bh4CiLS",
        "colab_type": "code",
        "outputId": "4d14c4bf-1d98-4c04-91f8-509baff702cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_OHLC.shape"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdMKELGg3Cve",
        "colab_type": "code",
        "outputId": "e7ab7ecf-1f47-4fdf-a4a1-992ddb668eb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "train_OHLC[:10]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.88034256],\n",
              "       [0.78632554],\n",
              "       [0.80769336],\n",
              "       [0.91453139],\n",
              "       [0.99145426],\n",
              "       [1.        ],\n",
              "       [0.89743671],\n",
              "       [0.87179575],\n",
              "       [0.931625  ],\n",
              "       [0.91453139]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbRvgCN-YDHB",
        "colab_type": "text"
      },
      "source": [
        "It turns out that the structure of the time series input data is similar to rolling_cv(), our prediction method will be similar as a result with the except that we lose the last time step value in the next iteration, so that one more relevent/recent time step value is taken into account.\n",
        "Altogether, we could be take larger time slices but in this case, we have chosen to take a single time step per iteration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWuQOlvs1TEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# method for transformation into 1d data\n",
        "\n",
        "# t_step_size == time step size\n",
        "\n",
        "def new_dataset(dataset, t_step_size):\n",
        "  data_X, data_Y = [], []\n",
        "  limit = len(dataset)-t_step_size-1\n",
        "\n",
        "  for i in range(limit):\n",
        "    j = i + t_step_size\n",
        "    #a = dataset.iloc[i:j, 0]\n",
        "    a = dataset[i:j, 0] #       row vector inputs \n",
        "    #print(a)\n",
        "    data_X.append(a) \n",
        "    #b = dataset.iloc[j, 0]\n",
        "    b = dataset[j, 0]   #       row vectors inputs\n",
        "    #print(b)\n",
        "    data_Y.append(b)\n",
        "  return np.asarray(data_X), np.asarray(data_Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wokKMO7g1JBJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# row vectors each with a single element, time slices: t              instead of t   t+1 t+2\n",
        "trainX, trainY = new_dataset(train_OHLC, 1) #          t+1                       t+3 t+3 t+5\n",
        "testX, testY = new_dataset(test_OHLC, 1)    #          t+2                       t+6 t+7 t+8\n",
        "                                            #                                    etc...\n",
        "# the values are just shifted up so t+1 is the starting position in trainY\n",
        "# and similarly t+n+1 is not in trainX but in trainY since that is the last\n",
        "# value to be predicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJWG5uYe5Iga",
        "colab_type": "code",
        "outputId": "56436294-6384-4d08-8d80-d457f12d0e67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "trainX[-10:-1]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.48718032],\n",
              "       [0.41880426],\n",
              "       [0.2820516 ],\n",
              "       [0.27350506],\n",
              "       [0.29914628],\n",
              "       [0.30769416],\n",
              "       [0.2820516 ],\n",
              "       [0.21367473],\n",
              "       [0.21367473]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiH-CcsWA_QH",
        "colab_type": "code",
        "outputId": "df600847-5a66-474d-f09f-ba839811bda3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "trainY[10:-1]"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.78632554, 0.81196703, 0.72649735, 0.52136702, 0.50427501,\n",
              "       0.41880426, 0.39316277, 0.25640984, 0.13675186, 0.27350506,\n",
              "       0.25640984, 0.35042739, 0.26495665, 0.2905984 , 0.31624043,\n",
              "       0.2820516 , 0.20512819, 0.24786303, 0.1452992 , 0.1111109 ,\n",
              "       0.23931729, 0.44444522, 0.43589841, 0.45299202, 0.48718032,\n",
              "       0.41880426, 0.2820516 , 0.27350506, 0.29914628, 0.30769416,\n",
              "       0.2820516 , 0.21367473, 0.21367473, 0.00854654])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urphe7dD5nYQ",
        "colab_type": "code",
        "outputId": "3614ac11-8aa6-433d-98bc-2405e8f889fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainX.shape"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YObYBRru1LTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape train, test data for input into model\n",
        "                            \n",
        "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1])) # (45,1,1) => \n",
        "                                                                   # (batch_size,time_steps, inp_dim)\n",
        "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
        "t_step_size = 1\n",
        "\n",
        "# matrix with 1 channel, in 3rd dimension\n",
        "# input taken in as row vector time slices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNkIdoHk5jiF",
        "colab_type": "code",
        "outputId": "48eb447d-6104-4ecb-ab6c-c02f4c0f29f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "trainX[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.88034256]],\n",
              "\n",
              "       [[0.78632554]],\n",
              "\n",
              "       [[0.80769336]],\n",
              "\n",
              "       [[0.91453139]],\n",
              "\n",
              "       [[0.99145426]],\n",
              "\n",
              "       [[1.        ]],\n",
              "\n",
              "       [[0.89743671]],\n",
              "\n",
              "       [[0.87179575]],\n",
              "\n",
              "       [[0.931625  ]],\n",
              "\n",
              "       [[0.91453139]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cwkq2z_V_RFS",
        "colab_type": "text"
      },
      "source": [
        "The architecture of the LSTM takes time slices over signals/columns/tickers sequentially but since we have only one ticker, which we aggregated from Open Close High Low prices. We have only one element row vectors. t, t+1, t+2,...,t+n for n time slices "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qe8pXIWq1a6H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lstm model\n",
        "\n",
        "\n",
        "# initializing rnn//\n",
        "model = Sequential()\n",
        "\n",
        "# input layer//\n",
        "# -- input layer with input_shape(1,1) => \n",
        "# 1 sequence(single time slice t, not i.e. [t,t+1,t+2]),\n",
        "# and 1 signal/column/price from a single ticker\n",
        "# 32 values(arbitrary neuron size for the hidden layer) will be output from a batch of size 1 \n",
        "model.add(LSTM(32, input_shape=(1, step_size), return_sequences = True))\n",
        "\n",
        "# hidden layer//\n",
        "# 32 values get mapped to an output with 16 values \n",
        "model.add(LSTM(16))\n",
        "\n",
        "\n",
        "# one final additional note regarding the diminishing number neurons. it is customary to do \n",
        "# as the final layer approaches for ease of tranformation to the dimension of the output layer\n",
        "\n",
        "# output layer//\n",
        "# finally, 16 values get mapped to a single value in the dense layer \n",
        "model.add(Dense(1))\n",
        "\n",
        "# activation will be 'linear' so all values will be mapped to the values \n",
        "# of a line to assist with optimization\n",
        "model.add(Activation('linear'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbKg_o-h-90d",
        "colab_type": "text"
      },
      "source": [
        "Fitting the model and calculating errors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qnrvncek1g_r",
        "colab_type": "code",
        "outputId": "38c799d6-048f-4999-d05a-cabb1a599f1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# compile model and train\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adagrad',metrics = ['mae']) \n",
        "# compare mae, adam, adagrad\n",
        "model.fit(trainX, trainY, epochs=50, batch_size=1, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            " - 2s - loss: 0.0969 - mean_absolute_error: 0.2339\n",
            "Epoch 2/50\n",
            " - 0s - loss: 0.0360 - mean_absolute_error: 0.1562\n",
            "Epoch 3/50\n",
            " - 0s - loss: 0.0309 - mean_absolute_error: 0.1551\n",
            "Epoch 4/50\n",
            " - 0s - loss: 0.0261 - mean_absolute_error: 0.1389\n",
            "Epoch 5/50\n",
            " - 0s - loss: 0.0220 - mean_absolute_error: 0.1266\n",
            "Epoch 6/50\n",
            " - 0s - loss: 0.0188 - mean_absolute_error: 0.1155\n",
            "Epoch 7/50\n",
            " - 0s - loss: 0.0163 - mean_absolute_error: 0.1072\n",
            "Epoch 8/50\n",
            " - 0s - loss: 0.0142 - mean_absolute_error: 0.0971\n",
            "Epoch 9/50\n",
            " - 0s - loss: 0.0125 - mean_absolute_error: 0.0900\n",
            "Epoch 10/50\n",
            " - 0s - loss: 0.0111 - mean_absolute_error: 0.0824\n",
            "Epoch 11/50\n",
            " - 0s - loss: 0.0101 - mean_absolute_error: 0.0795\n",
            "Epoch 12/50\n",
            " - 0s - loss: 0.0092 - mean_absolute_error: 0.0774\n",
            "Epoch 13/50\n",
            " - 0s - loss: 0.0086 - mean_absolute_error: 0.0721\n",
            "Epoch 14/50\n",
            " - 0s - loss: 0.0081 - mean_absolute_error: 0.0713\n",
            "Epoch 15/50\n",
            " - 0s - loss: 0.0078 - mean_absolute_error: 0.0687\n",
            "Epoch 16/50\n",
            " - 0s - loss: 0.0075 - mean_absolute_error: 0.0684\n",
            "Epoch 17/50\n",
            " - 0s - loss: 0.0073 - mean_absolute_error: 0.0661\n",
            "Epoch 18/50\n",
            " - 0s - loss: 0.0071 - mean_absolute_error: 0.0670\n",
            "Epoch 19/50\n",
            " - 0s - loss: 0.0070 - mean_absolute_error: 0.0647\n",
            "Epoch 20/50\n",
            " - 0s - loss: 0.0069 - mean_absolute_error: 0.0654\n",
            "Epoch 21/50\n",
            " - 0s - loss: 0.0069 - mean_absolute_error: 0.0654\n",
            "Epoch 22/50\n",
            " - 0s - loss: 0.0069 - mean_absolute_error: 0.0655\n",
            "Epoch 23/50\n",
            " - 0s - loss: 0.0068 - mean_absolute_error: 0.0644\n",
            "Epoch 24/50\n",
            " - 0s - loss: 0.0068 - mean_absolute_error: 0.0644\n",
            "Epoch 25/50\n",
            " - 0s - loss: 0.0068 - mean_absolute_error: 0.0638\n",
            "Epoch 26/50\n",
            " - 0s - loss: 0.0067 - mean_absolute_error: 0.0638\n",
            "Epoch 27/50\n",
            " - 0s - loss: 0.0067 - mean_absolute_error: 0.0645\n",
            "Epoch 28/50\n",
            " - 0s - loss: 0.0067 - mean_absolute_error: 0.0640\n",
            "Epoch 29/50\n",
            " - 0s - loss: 0.0065 - mean_absolute_error: 0.0620\n",
            "Epoch 30/50\n",
            " - 0s - loss: 0.0067 - mean_absolute_error: 0.0637\n",
            "Epoch 31/50\n",
            " - 0s - loss: 0.0067 - mean_absolute_error: 0.0636\n",
            "Epoch 32/50\n",
            " - 0s - loss: 0.0067 - mean_absolute_error: 0.0645\n",
            "Epoch 33/50\n",
            " - 0s - loss: 0.0067 - mean_absolute_error: 0.0645\n",
            "Epoch 34/50\n",
            " - 0s - loss: 0.0067 - mean_absolute_error: 0.0643\n",
            "Epoch 35/50\n",
            " - 0s - loss: 0.0067 - mean_absolute_error: 0.0638\n",
            "Epoch 36/50\n",
            " - 0s - loss: 0.0067 - mean_absolute_error: 0.0629\n",
            "Epoch 37/50\n",
            " - 0s - loss: 0.0067 - mean_absolute_error: 0.0633\n",
            "Epoch 38/50\n",
            " - 0s - loss: 0.0067 - mean_absolute_error: 0.0636\n",
            "Epoch 39/50\n",
            " - 0s - loss: 0.0067 - mean_absolute_error: 0.0630\n",
            "Epoch 40/50\n",
            " - 0s - loss: 0.0067 - mean_absolute_error: 0.0636\n",
            "Epoch 41/50\n",
            " - 0s - loss: 0.0067 - mean_absolute_error: 0.0633\n",
            "Epoch 42/50\n",
            " - 0s - loss: 0.0067 - mean_absolute_error: 0.0634\n",
            "Epoch 43/50\n",
            " - 0s - loss: 0.0067 - mean_absolute_error: 0.0635\n",
            "Epoch 44/50\n",
            " - 0s - loss: 0.0067 - mean_absolute_error: 0.0645\n",
            "Epoch 45/50\n",
            " - 0s - loss: 0.0067 - mean_absolute_error: 0.0636\n",
            "Epoch 46/50\n",
            " - 0s - loss: 0.0067 - mean_absolute_error: 0.0627\n",
            "Epoch 47/50\n",
            " - 0s - loss: 0.0067 - mean_absolute_error: 0.0629\n",
            "Epoch 48/50\n",
            " - 0s - loss: 0.0067 - mean_absolute_error: 0.0630\n",
            "Epoch 49/50\n",
            " - 0s - loss: 0.0067 - mean_absolute_error: 0.0623\n",
            "Epoch 50/50\n",
            " - 0s - loss: 0.0066 - mean_absolute_error: 0.0630\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7487b214a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqYscweX1iND",
        "colab_type": "code",
        "outputId": "f62bf159-3eb9-4dc0-d156-85e7a9b2159b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# evaluate model accuracy\n",
        "\n",
        "mae = model.evaluate(testX, testY, batch_size=16)\n",
        "print('MAE:', mae)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r14/14 [==============================] - 1s 55ms/step\n",
            "MAE: [0.004918854217976332, 0.05656498670578003]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNlDt5Hx6h_k",
        "colab_type": "text"
      },
      "source": [
        "# Mean Absolute Error and Mean Absolute Percentage Error are differ in formulae. So we will not compare MAPE from the previous models with LSTM. And we'll say an error of .057 or 5.7% is good. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuJGZRIsoEf2",
        "colab_type": "text"
      },
      "source": [
        "# To Summarize the previous results with MAPE metrics: Facebook performed the worst using rolling_cv() with 36.88% error and AutoArima performed the best with 1.5% error\n"
      ]
    }
  ]
}